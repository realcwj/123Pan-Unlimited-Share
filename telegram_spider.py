import requests
import json
import os
from bs4 import BeautifulSoup
import urllib.parse
from tqdm import tqdm
from Pan123 import Pan123

def getContent(channel_name, after_id, debug=False):

    base_url = f"https://t.me/s/{channel_name}"
    
    headers = {
        'Accept': 'application/json, text/javascript, */*; q=0.01',
        'Accept-Encoding': 'gzip, deflate, br, zstd',
        'Accept-Language': 'en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7',
        'Cookie': 'stel_ssid=114514', # å¾…ç ”ç©¶
        'DNT': '1',
        'Origin': 'https://t.me',
        'Priority': 'u=1, i',
        'Sec-CH-UA': '"Chromium";v="136", "Google Chrome";v="136", "Not.A/Brand";v="99"',
        'Sec-CH-UA-Mobile': '?0',
        'Sec-CH-UA-Platform': '"Windows"',
        'Sec-Fetch-Dest': 'empty',
        'Sec-Fetch-Mode': 'cors',
        'Sec-Fetch-Site': 'same-origin',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36',
        'X-Requested-With': 'XMLHttpRequest'
    }

    request_url = f"{base_url}?after={after_id}"

    # è®¾ç½®åŠ¨æ€ Referer
    # headers['Referer'] = f"{base_url}?after={after_id - 22}" # å¾…ç ”ç©¶, ä¼¼ä¹å·®å€¼æ˜¯å›ºå®š22
    # è¿™ä¸ªä¼¼ä¹ä¸é‡è¦ï¼Ÿï¼Ÿï¼Ÿ

    response = requests.post(request_url, headers=headers, data="", timeout=10)
    response.raise_for_status()  # å¯¹ 4XX æˆ– 5XX å“åº”ä¼šæŠ›å‡º HTTPError
    
    xml_data = json.loads(response.text)
    
    # return xml_data
    
    if debug:
        print(f"è¯·æ±‚ï¼š{request_url}")
        # print(f"å“åº”ï¼š{response.text}")
    
    # è¿”å›çš„å†…å®¹æœ‰ä»¥ä¸‹å‡ ç§æƒ…å†µï¼š
    ## ç¬¬ä¸€ç§ï¼šåé¢è¿˜æœ‰ä¸œè¥¿ï¼Œå­˜åœ¨"tgme_widget_message_centered js-messages_more_wrap"å­—æ®µï¼ŒæŒ‡å‘ä¸‹ä¸€é¡µ
    ## ç¬¬äºŒç§ï¼šåé¢è¿˜æœ‰ä¸œè¥¿ï¼Œä½†æ˜¯ä¸è¶³20æ¡ï¼Œä¸å­˜åœ¨"tgme_widget_message_centered js-messages_more_wrap"å­—æ®µ
    ## ç¬¬ä¸‰ç§ï¼šå•¥éƒ½æ²¡æœ‰ï¼Œxml_data=""
    
    # å¤„ç†ç¬¬ä¸‰ç§æƒ…å†µ
    if xml_data == "":
        return {}, None

    # å­˜å‚¨æ¶ˆæ¯å†…å®¹ï¼š{int(id): "<div>...</div>", int(id): "<div>...</div>", ...}
    message_dict = {}
    
    xml_data = xml_data.split("\n")
    pos = 0
    while pos < len(xml_data):
        line = xml_data[pos]
        
        if "tgme_widget_message_text js-message_text" in line:
            # å‘åå‡ è¡Œå¯»æ‰¾ f"https://t.me/{channel_name}/" (messageåº•éƒ¨, æ˜¾ç¤ºxxäººå·²è§‚çœ‹çš„ä½ç½®)
            id_keyword = f"https://t.me/{channel_name}/"
            pos += 1 # ä»ä¸‹ä¸€è¡Œå¼€å§‹æœç´¢
            current_message_id = None
            while pos < len(xml_data):
                search_line = xml_data[pos]
                if id_keyword in search_line:
                    current_message_id = search_line.split(id_keyword)[1].split("\"")[0]
                    current_message_id = int(current_message_id) # è½¬æ¢ä¸º int, æ­¤å¤„è¿˜å¯ä»¥ç¡®ä¿åˆ†å‰²æ­£ç¡®
                    break
                pos += 1
            if current_message_id is None:
                raise ValueError("æ‰¾ä¸åˆ°æ¶ˆæ¯id")
            else:
                message_dict[current_message_id] = line
            if debug:
                print(f"å­˜å‚¨æ¶ˆæ¯ï¼š{current_message_id}")
            continue
        # å¤„ç†ç¬¬ä¸€ç§æƒ…å†µ
        elif "tgme_widget_message_centered js-messages_more_wrap" in line:
            # æˆªå– data-after="xxxx" ä¸­çš„ xxxx
            line = line.split("data-after=\"")[1].split("\"")[0]
            line = int(line) # è½¬æ¢ä¸º int, æ­¤å¤„è¿˜å¯ä»¥ç¡®ä¿åˆ†å‰²æ­£ç¡®
            if debug:
                print(f"ä¸‹ä¸€é¡µï¼š{line}")
            return message_dict, line
        else:
            pos+=1
            continue

    # å¤„ç†ç¬¬äºŒç§æƒ…å†µ
    return message_dict, None

def beautifyXML(xml_text):
    # ä½¿ç”¨ BeautifulSoup è§£æ HTML
    soup = BeautifulSoup(xml_text, 'html.parser')
    # è·å–æ¯è¡Œçš„æ–‡æœ¬
    text_content = soup.get_text(separator='\n', strip=True)
    lines = [line.strip() for line in text_content.split('\n') if line.strip()]
    # è·å–æ‰€æœ‰çš„é“¾æ¥
    links = []
    for a_tag in soup.find_all('a', href=True):
        raw_link = a_tag['href']
        decoded_link = urllib.parse.unquote(raw_link) # Decode the URL
        links.append(decoded_link)

    return lines + links

def getNameLinkPwd(content_list, debug=False):
    # ä¹±ä¸ƒå…«ç³Ÿçš„, æœ‰æ²¡æœ‰å¤§ä½¬å¸®å¿™ä¼˜åŒ–ä¸€ä¸‹
    name = content_list[0]
    if any([i in name for i in ["automatically deleted", "com/s/", "æ— æ³•è¿›å…¥ç¾¤èŠ"]]):
        name = ""
    link = ""
    pwd = ""
    for line in content_list:
        # æ›¿æ¢ä¸­æ–‡ç¬¦å·
        line = line.replace("ï¼Ÿ", "?").replace("ï¼", "!").replace("ï¼š", ":").replace("ï¼Œ", ",").replace("ã€‚", ".").replace("ï¼ˆ", "(").replace("ï¼‰", ")")
        if "åç§°" in line[:20]:
            name = line.split(":")[-1]
            if debug:
                print("è¿™é‡Œæ›¿æ¢äº†nameå˜é‡")
                print(f"åŸæ–‡>>>{line}")
                print(f"åç§°>>>{name}")
        elif "/s/" in line:
            line = line.replace("æå–ç ", "?æå–ç ")
            if debug:
                print(f"åŸæ–‡>>>{line}")
            line = line.split(".com/s/")[1]
            if debug:
                print(f"é“¾æ¥>>>{line}")
            if "æå–ç " in line:
                link = line.split("?")[0]
                pwd = line.split(":")[1]
            else:
                link = line.strip()
    # æœ‰çš„æ–‡ä»¶åæœ‰å¤šä¸ªç©ºæ ¼, æ›¿æ¢ä¸ºä¸€ä¸ªç©ºæ ¼
    name = name.replace("  ", " ").replace("  ", " ").replace("  ", " ")
    return {"name": name, "link": link, "pwd": pwd}

def startSpider(channel_name, message_after_id=None, save_interval=10, debug=False):

    # å¦‚æœæ²¡æœ‰å¡«å†™channel_name, ç›´æ¥è·³è¿‡
    if not channel_name:
        print("[Telegramçˆ¬è™«] æ²¡æœ‰å¡«å†™channel_name, ç›´æ¥è·³è¿‡")
        return
    
    # è¯·æ³¨æ„: å…¬å…±èµ„æºåº“ä¸æ”¯æŒæ¥è‡ªä¸­å›½å¤§é™†IPåœ°å€çš„ç”¨æˆ·!
    # è¯·æ³¨æ„: å…¬å…±èµ„æºåº“ä¸æ”¯æŒæ¥è‡ªä¸­å›½å¤§é™†IPåœ°å€çš„ç”¨æˆ·!
    # è¯·æ³¨æ„: å…¬å…±èµ„æºåº“ä¸æ”¯æŒæ¥è‡ªä¸­å›½å¤§é™†IPåœ°å€çš„ç”¨æˆ·!
    
    # æ£€æŸ¥IP, å¦‚æœæ˜¯ä¸­å›½çš„, é€€å‡ºç¨‹åº
    # å½“ä½ çœ‹åˆ°è¿™é‡Œ, è¯·ä¸è¦å°è¯•åˆ é™¤æœ¬æ®µä»£ç , å¼ºè¡Œè¿è¡Œ, ä¸æ”¯æŒçš„IPåœ°å€æ˜¯æ²¡æ³•è¿è¡Œåç»­ç¨‹åºçš„!
    check_ip_url = "https://ipv4.ping0.cc/geo"
    response = requests.get(check_ip_url).text
    if "ä¸­å›½" in response and not any(keyword in response for keyword in ["é¦™æ¸¯", "æ¾³é—¨", "å°æ¹¾"]):
            print(f"ä¸æ”¯æŒå½“å‰IPåœ°å€ä½¿ç”¨ï¼š\n\n{response}")
            exit(0)
    else:
        print(f"å½“å‰IPåœ°å€æ”¯æŒä½¿ç”¨ï¼š\n\n{response}")

    file_path = f"{channel_name}_message_raw.json"
    total_json_raw_data = {}
    next_page = message_after_id

    if os.path.exists(file_path):
        if message_after_id is not None:
            print("å·²å­˜åœ¨Jsonæ–‡ä»¶, å¼ºåˆ¶message_after_id=None, ä»Jsonæ–‡ä»¶ä¸­è¯»å–æœ€å¤§çš„ä¸€ä¸ªæ•°å­—å¼€å§‹çˆ¬")
            message_after_id = None
        with open(file_path, "r", encoding="utf-8") as f:
            total_json_raw_data = json.load(f)
        # ä»Jsonçš„æœ€å¤§çš„ä¸€ä¸ªæ•°å­—å¼€å§‹çˆ¬
        next_page = max(total_json_raw_data.keys())

    count = 0
    while True:
        print(f"çˆ¬å–ç¬¬{int(next_page)+1}æ¡message")
        message_dict, next_page = getContent(
            channel_name=channel_name,
            after_id=next_page,
            debug=debug
        )
        total_json_raw_data.update(message_dict)
        count += 1
        if count % save_interval == 0:
            # ä¿å­˜åˆ°Jsonæ–‡ä»¶
            print(f"è§¦å‘é—´éš”{save_interval}, ä¿å­˜åˆ°Jsonæ–‡ä»¶")
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(total_json_raw_data, f, ensure_ascii=False, indent=4)
        # é€€å‡ºæ¡ä»¶: next_page is Noneï¼ˆæ²¡æœ‰ä¸‹ä¸€é¡µäº†ï¼‰
        if next_page is None:
            break
    # ä¿å­˜åˆ°Jsonæ–‡ä»¶
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(total_json_raw_data, f, ensure_ascii=False, indent=4)

    # ç”¨äºä¿å­˜å¤„ç†åçš„æ•°æ®
    total_json_processed_data = {}

    # æ•°æ®æ¸…æ´—ï¼Œæ‰¹é‡å¾—åˆ°name, link, pwd
    for key, value in tqdm(total_json_raw_data.items(), desc="è·å–èµ„æºåç§°/é“¾æ¥/å¯†ç ä¸­..."):
        result = getNameLinkPwd(beautifyXML(value), debug=debug)
        if len(result.get("name")) and len(result.get("link")):
            total_json_processed_data[key] = result
    
    # åˆ é™¤total_json_raw_data(åé¢ä¹Ÿç”¨ä¸åˆ°äº†), é˜²æ­¢å†…å®¹å¤ªå¤šçˆ†å†…å­˜
    del total_json_raw_data
    
    # ä¿å­˜åˆ°Jsonæ–‡ä»¶
    with open(f"{channel_name}_message_processed.json", "w", encoding="utf-8") as f:
        json.dump(total_json_processed_data, f, ensure_ascii=False, indent=4)
    
    # è°ƒç”¨ Pan123 å¯¼å‡º *.123share åˆ°å…¬å…±èµ„æºåº“
    driver = Pan123(debug=debug)
    for key, value in total_json_processed_data.items():
        # å¦‚æœnameå·²ç»å­˜åœ¨, åˆ™è·³è¿‡
        if os.path.exists(f"./public/ok/{value.get('name')}.123share"):
            if debug:
                print(f"[{key}] è·³è¿‡ï¼š{value.get('name')}, åŸå› ï¼šæ–‡ä»¶å·²å­˜åœ¨")
            continue
        print(f"[{key}] å¯¼å‡ºæ–°å¢å†…å®¹ï¼š{value.get('name')}")
        iter_driver = driver.exportShare(shareKey=value.get("link"), sharePwd=value.get("pwd"), parentFileId=0)
        for current_state in iter_driver:
            if current_state.get("isFinish"):
                with open(f"./public/ok/{value.get('name')}.123share", "w") as f:
                    f.write(current_state.get("message"))
                print(f"[{key}] å¯¼å‡ºæˆåŠŸï¼š{value.get('name')}")
            elif current_state.get("isFinish") is None:
                continue
            else:
                print(f"[{key}] å¯¼å‡ºå¤±è´¥ï¼š{value.get('name')}, åŸå› ï¼š{current_state.get('message')}")
                break

if __name__ == "__main__":

    channel_name = "" # å¤§å®¶åº”è¯¥éƒ½çŸ¥é“æ˜¯telegramçš„å“ªä¸ªç¾¤, è‡ªå·±å¡«å…¥ï¼ˆ@xxxxçš„xxxxéƒ¨åˆ†ï¼‰, GitHubä¸æ˜è¯´äº†
    message_after_id = 8050 # ä» 8050 å¼€å§‹çˆ¬, å› ä¸ºä¹‹å‰çš„å†…å®¹ã€å…¨ã€‘ã€éƒ½ã€‘ã€å¤±ã€‘ã€æ•ˆã€‘ã€äº†ã€‘

    startSpider(channel_name=channel_name, message_after_id=message_after_id, debug=False)

    # text = "<div class=\"tgme_widget_message_text js-message_text\" dir=\"auto\">åç§°ï¼šã€Šæµ´è¡€é»‘å¸®ï¼ˆ2013ï¼‰ã€‹å…¨6å­£1080pè“å…‰åŸç›˜REMUX å†…å°ç‰¹æ•ˆå­—å¹•<br/><br/>æè¿°ï¼šã€Šæµ´è¡€é»‘å¸®ã€‹è®²è¿°äº†æˆ˜åä¼¯æ˜ç¿°åœ°åŒºä¼ å¥‡é»‘å¸®å®¶æ—Peaky Blindersçš„æ•…äº‹ã€‚æ—¶é—´è¦è¿½æº¯åˆ°1919å¹´ï¼Œå®¶æ—æˆå‘˜æœ‰ä¸€å¤§å—œå¥½ï¼Œå°±æ˜¯å°†å‰ƒåˆ€åˆ€ç‰‡ç¼è¿›ä»–ä»¬å¸½å­çš„å¸½æªä¹‹é—´ï¼Œè¿™ä¹Ÿæ˜¯â€œå‰ƒåˆ€å…šâ€çš„åç§°ç”±æ¥ã€‚æ–¯é‡Œå®‰Â·å¢¨è²å°†é¥°æ¼”ä¸€åæ®‹é…·çš„é»‘å¸®ä»½å­Tommy Shelby ï¼Œæ˜¯å®¶æ—å…„å¼Ÿçš„é¢†è¢–ï¼Œå—œè¡€æ— æƒ…ã€‚åœ¨é‚£ä¸ªæ—¶ä»£ï¼Œé€€ä¼å†›äººã€é©å‘½è€…å’Œç½ªçŠ¯ï¼Œéƒ½åœ¨ç¤¾ä¼šåº•å±‚æŒ£æ‰ç”Ÿå­˜ã€‚è€Œå½“è´å°”æ³•æ–¯ç‰¹çš„è­¦æ–¹è´Ÿè´£äººå¼€å§‹ä»‹å…¥æ—¶ï¼ŒTommyå’Œä»–çš„é»‘å¸®åŠ¿åŠ›åˆ¶é€ å‡ºçš„ææ€–ç»Ÿæ²»å¼€å§‹äº†å€¾æ–œ<br/><br/>é“¾æ¥ï¼š&nbsp;<a href=\"https://www.123912.com/s/IpPUVv-GXOj?%E6%8F%90%E5%8F%96%E7%A0%81:JZMM\" target=\"_blank\" rel=\"noopener\">https://www.123912.com/s/IpPUVv-GXOj?æå–ç :JZMM</a><br/><br/><i class=\"emoji\" style=\"background-image:url('//telegram.org/img/emoji/40/F09F8FB7.png')\"><b>ğŸ·</b></i> æ ‡ç­¾ï¼š<a href=\"?q=%23%E5%8E%9F%E7%9B%98REMUX\">#åŸç›˜REMUX</a> <a href=\"?q=%23%E8%8B%B1%E5%89%A7\">#è‹±å‰§</a> <a href=\"?q=%23%E5%89%A7%E6%83%85\">#å‰§æƒ…</a><br/><i class=\"emoji\" style=\"background-image:url('//telegram.org/img/emoji/40/F09F9381.png')\"><b>ğŸ“</b></i> å¤§å°ï¼š451.18GB<br/><i class=\"emoji\" style=\"background-image:url('//telegram.org/img/emoji/40/F09F8E89.png')\"><b>ğŸ‰</b></i> æ¥è‡ªï¼š<a href=\"https://t.me/juziminmao\" target=\"_blank\">@juziminmao</a></div>"
    # text = beautifyXML(text)
    # text = getNameLinkPwd(text, debug=True)
    # print(text)